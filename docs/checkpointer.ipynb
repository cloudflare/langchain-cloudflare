{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Cloudflare D1 checkpointer for persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites\n",
    "\n",
    "The guide assumes familiary with the following:\n",
    "\n",
    "* [Persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/)\n",
    "* [Cloudflare D1](https://developers.cloudflare.com/d1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating LangGraph agents, you can also set them up so that they persist their state. This allows you to do things like interact with an agent multiple times and have it remember previous interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reference implementation shows how to use Cloudflare's D1 serverless database as the backend for persisting checkpoint state using the `langgraph-checkpoint-cloudflare-d1` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes we add persistence to a [prebuilt ReAct agent](https://langchain-ai.github.io/langgraph/agents/agents/#basic-configuration)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Cloudflare D1 checkpointer, you will need a Cloudflare D1 database. Follow this [guide](https://developers.cloudflare.com/d1/get-started/) to create a database if you don't already have one.\n",
    "\n",
    "Next, let's install the required packages and set our API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U requests httpx langgraph langgraph-checkpoint-cloudflare-d1"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"CF_API_KEY\"):\n",
    "    os.environ[\"CF_API_KEY\"] = getpass.getpass(\"Enter your CloudflareWorkersAI API key: \")\n",
    "\n",
    "if not os.getenv(\"CF_ACCOUNT_ID\"):\n",
    "    os.environ[\"CF_ACCOUNT_ID\"] = getpass.getpass(\"Enter your Cloudflare account ID: \")\n",
    "\n",
    "if not os.getenv(\"CF_D1_API_TOKEN\"):\n",
    "    os.environ[\"CF_D1_API_TOKEN\"] = getpass.getpass(\"Enter your Cloudflare D1 API token: \")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you'd like to use Cloudflare's WorkersAI, use the following:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%pip install -qU langchain-cloudflare"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if not os.getenv(\"CF_API_KEY\"):\n",
    "    os.environ[\"CF_API_KEY\"] = getpass.getpass(\"Enter your CloudflareWorkersAI API key: \")"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T20:17:11.176614Z",
     "start_time": "2025-05-10T20:17:10.894772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_cloudflare import ChatCloudflareWorkersAI\n",
    "\n",
    "model = ChatCloudflareWorkersAI(\n",
    "    model=\"@cf/meta/llama-3.3-70b-instruct-fp8-fast\",\n",
    "    temperature=0,\n",
    "    max_tokens=1024\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Otherwise you can use another LLM provider like below"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OPENAI API Key: \")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Set up [LangSmith](https://smith.langchain.com/) for LangGraph development\n",
    "\n",
    "Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started [here](https://docs.smith.langchain.com/)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define model and tools for the graph"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T20:17:19.262345Z",
     "start_time": "2025-05-10T20:17:19.204173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cloudflare D1 checkpointer usage"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T20:19:01.614103Z",
     "start_time": "2025-05-10T20:18:54.519203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph_checkpoint_cloudflare_d1 import CloudflareD1Saver\n",
    "\n",
    "checkpointer = CloudflareD1Saver()\n",
    "\n",
    "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "response = graph.invoke(\n",
    "    {\"messages\": [(\"human\", \"what's the weather in sf\")]}, config\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Async"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T20:19:41.584444Z",
     "start_time": "2025-05-10T20:19:37.119785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph_checkpoint_cloudflare_d1 import AsyncCloudflareD1Saver\n",
    "\n",
    "checkpointer = AsyncCloudflareD1Saver()\n",
    "\n",
    "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "response = await graph.ainvoke(\n",
    "    {\"messages\": [(\"human\", \"what's the weather in sf\")]}, config\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 14
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
