{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CloudflareVectorize\n",
    "This notebook demonstrates how to setup and use Cloudflare's Vectorize wrapper for LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:36:00.955411Z",
     "start_time": "2025-04-02T20:36:00.728379Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import uuid\n",
    "import warnings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_cloudflare.embeddings import (\n",
    "    CloudflareWorkersAIEmbeddings,\n",
    ")\n",
    "from langchain_cloudflare.vectorstores import (\n",
    "    CloudflareVectorize,\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### API Tokens\n",
    "\n",
    "This Python package is a wrapper around Cloudflare's REST API.  To interact with the API, you need to provid an API token with the appropriate privileges.\n",
    "\n",
    "You can create and manage API tokens here:\n",
    "\n",
    "https://dash.cloudflare.com/YOUR-ACCT-NUMBER/api-tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Note:**\n",
    "CloudflareVectorize depends on WorkersAI (if you want to use it for Embeddings), and D1 (if you are using it to store and retrieve raw values).\n",
    "\n",
    "While you can create a single `api_token` with Edit privileges to all needed resources (WorkersAI, Vectorize & D1), you may want to follow the principle of \"least privilege access\" and create separate API tokens for each service\n",
    "\n",
    "**Note:** These service-specific tokens (if provided) will take preference over a global token.  You could provide these instead of a global token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:36:00.977229Z",
     "start_time": "2025-04-02T20:36:00.975208Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_acct_id = os.getenv(\"cf_acct_id\")\n",
    "\n",
    "# single token with WorkersAI, Vectorize & D1\n",
    "api_token = os.getenv(\"api_token\")\n",
    "\n",
    "# OR, separate tokens with access to each service\n",
    "cf_vectorize_token = os.getenv(\"cf_vectorize_token\")\n",
    "cf_d1_token = os.getenv(\"d1_api_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:36:01.061750Z",
     "start_time": "2025-04-02T20:36:01.059648Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# name your vectorize index\n",
    "vectorize_index_name = f\"test-langchain-{uuid.uuid4().hex}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Embeddings\n",
    "\n",
    "For storage of embeddings, semantic search and retrieval, you must embed your raw values as embeddings.  Specify an embedding model, one available on WorkersAI\n",
    "\n",
    "[https://developers.cloudflare.com/workers-ai/models/](https://developers.cloudflare.com/workers-ai/models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:36:01.067445Z",
     "start_time": "2025-04-02T20:36:01.065802Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODEL_WORKERSAI = \"@cf/baai/bge-large-en-v1.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:36:01.074397Z",
     "start_time": "2025-04-02T20:36:01.072407Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf_ai_token = os.getenv(\n",
    "    \"cf_ai_token\"\n",
    ")  # needed if you want to use workersAI for embeddings\n",
    "\n",
    "embedder = CloudflareWorkersAIEmbeddings(\n",
    "    account_id=cf_acct_id, api_token=cf_ai_token, model_name=MODEL_WORKERSAI\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Raw Values with D1\n",
    "\n",
    "Vectorize only stores embeddings, metadata and namespaces. If you want to store and retrieve raw values, you must leverage Cloudflare's SQL Database D1.\n",
    "\n",
    "You can create a database here and retrieve its id:\n",
    "\n",
    "[https://dash.cloudflare.com/YOUR-ACCT-NUMBER/workers/d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:36:01.122057Z",
     "start_time": "2025-04-02T20:36:01.120142Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# provide the id of your D1 Database\n",
    "d1_database_id = \"8ce9ce08-8961-475c-98fb-1ef0e6e4ca40\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### CloudflareVectorize Class\n",
    "\n",
    "Now we can create the CloudflareVectorize instance.  Here we passed:\n",
    "\n",
    "* The `embedding` instance from earlier\n",
    "* The account ID\n",
    "* A global API token for all services (WorkersAI, Vectorize, D1)\n",
    "* Individual API tokens for each service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:36:01.159302Z",
     "start_time": "2025-04-02T20:36:01.157178Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfVect = CloudflareVectorize(\n",
    "    embedding=embedder,\n",
    "    account_id=cf_acct_id,\n",
    "    d1_api_token=cf_d1_token,  # (Optional if using global token)\n",
    "    vectorize_api_token=cf_vectorize_token,  # (Optional if using global token)\n",
    "    d1_database_id=d1_database_id,  # (Optional if not using D1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Before we get started, let's delete any `test-langchain*` indexes we have for this walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:36:04.796395Z",
     "start_time": "2025-04-02T20:36:01.168767Z"
    }
   },
   "outputs": [],
   "source": [
    "# depending on your notebook environment you might need to include:\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "arr_indexes = cfVect.list_indexes()\n",
    "arr_indexes = [x for x in arr_indexes if \"test-langchain\" in x.get(\"name\")]\n",
    "arr_async_requests = [\n",
    "    cfVect.adelete_index(index_name=x.get(\"name\")) for x in arr_indexes\n",
    "]\n",
    "await asyncio.gather(*arr_async_requests);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Gotchyas\n",
    "\n",
    "A few \"gotchyas\" are shown below for various missing token/parameter combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "D1 Database ID provided but no \"global\" `api_token` and no `d1_api_token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    cfVect = CloudflareVectorize(\n",
    "        embedding=embedder,\n",
    "        account_id=cf_acct_id,\n",
    "        # api_token=api_token, # (Optional if using service-specific token)\n",
    "        ai_api_token=cf_ai_token,  # (Optional if using global token)\n",
    "        # d1_api_token=cf_d1_token,  # (Optional if using global token)\n",
    "        vectorize_api_token=cf_vectorize_token,  # (Optional if using global token)\n",
    "        d1_database_id=d1_database_id,  # (Optional if not using D1)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "No \"global\" `api_token` provided and either missing `ai_api_token` or `vectorize_api_token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    cfVect = CloudflareVectorize(\n",
    "        embedding=embedder,\n",
    "        account_id=cf_acct_id,\n",
    "        # api_token=api_token, # (Optional if using service-specific token)\n",
    "        # ai_api_token=cf_ai_token,  # (Optional if using global token)\n",
    "        d1_api_token=cf_d1_token,  # (Optional if using global token)\n",
    "        vectorize_api_token=cf_vectorize_token,  # (Optional if using global token)\n",
    "        d1_database_id=d1_database_id,  # (Optional if not using D1)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Manage Vector Store\n",
    "\n",
    "### Creating an Index\n",
    "\n",
    "Let's start off this example by creating and index (and first deleting if it exists).  If the index doesn't exist we will get a an error from Cloudflare telling us so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "try:\n",
    "    cfVect.delete_index(index_name=vectorize_index_name, wait=True)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = cfVect.create_index(index_name=vectorize_index_name, wait=True)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Listing Indexes\n",
    "\n",
    "Now, we can list our indexes on our account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexes = cfVect.list_indexes()\n",
    "indexes = [x for x in indexes if \"test-langchain\" in x.get(\"name\")]\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Get Index Info\n",
    "We can also get certain indexes and retrieve more granular information about an index.\n",
    "\n",
    "This call returns a `processedUpToMutation` which can be used to track the status of operations such as creating indexes, adding or deleting records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = cfVect.get_index_info(index_name=vectorize_index_name)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Adding Metadata Indexes\n",
    "\n",
    "It is common to assist retrieval by supplying metadata filters in quereies.  In Vectorize, this is accomplished by first creating a \"metadata index\" on your Vectorize Index.  We will do so for our example by creating one on the `section` field in our documents.\n",
    "\n",
    "**Reference:** [https://developers.cloudflare.com/vectorize/reference/metadata-filtering/](https://developers.cloudflare.com/vectorize/reference/metadata-filtering/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = cfVect.create_metadata_index(\n",
    "    property_name=\"section\",\n",
    "    index_type=\"string\",\n",
    "    index_name=vectorize_index_name,\n",
    "    wait=True,\n",
    ")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing Metadata Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = cfVect.list_metadata_indexes(index_name=vectorize_index_name)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Adding Documents\n",
    "For this example, we will use LangChain's Wikipedia loader to pull an article about Cloudflare.  We will store this in Vectorize and query its contents later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:40:04.112253Z",
     "start_time": "2025-04-02T20:40:03.130147Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = WikipediaLoader(query=\"Cloudflare\", load_max_docs=2).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will then create some simple chunks with metadata based on the chunk sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:40:04.575521Z",
     "start_time": "2025-04-02T20:40:04.572033Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "texts = text_splitter.create_documents([docs[0].page_content])\n",
    "\n",
    "running_section = \"\"\n",
    "for idx, text in enumerate(texts):\n",
    "    if text.page_content.startswith(\"=\"):\n",
    "        running_section = text.page_content\n",
    "        running_section = running_section.replace(\"=\", \"\").strip()\n",
    "    else:\n",
    "        if running_section == \"\":\n",
    "            text.metadata = {\"section\": \"Introduction\"}\n",
    "        else:\n",
    "            text.metadata = {\"section\": running_section}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:40:05.213892Z",
     "start_time": "2025-04-02T20:40:05.211729Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "page_content='Cloudflare, Inc., is an American company that provides content delivery network services,' metadata={'section': 'Introduction'} \n",
      "\n",
      " page_content='attacks, Cloudflare ended up being attacked as well; Google and other companies eventually' metadata={'section': 'DDoS mitigation'}\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))\n",
    "print(texts[0], \"\\n\\n\", texts[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we will add documents to our Vectorize Index.\n",
    "\n",
    "**Note:**\n",
    "Adding embeddings to Vectorize happens `asyncronously`, meaning there will be a small delay between adding the embeddings and being able to query them.  By default `add_documents` has a `wait=True` parameter which waits for this operation to complete before returning a response.  If you do not want the program to wait for embeddings availability, you can set this to `wait=False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = cfVect.add_documents(index_name=vectorize_index_name, documents=texts, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(json.dumps(r)[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Query vector store\n",
    "\n",
    "We will do some searches on our embeddings.  We can specify our search `query` and the top number of results we want with `k`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_documents = cfVect.similarity_search(\n",
    "    index_name=vectorize_index_name, query=\"Workers AI\", k=100, return_metadata=\"none\"\n",
    ")\n",
    "\n",
    "print(f\"{len(query_documents)} results:\\n{query_documents[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Output\n",
    "\n",
    "If you want to return metadata you can pass `return_metadata=\"all\" | 'indexed'`.  The default is `all`.\n",
    "\n",
    "If you want to return the embeddings values, you can pass `return_values=True`.  The default is `False`.\n",
    "Embeddings will be returned in the `metadata` field under the special `_values` field.\n",
    "\n",
    "**Note:** `return_metadata=\"none\"` and `return_values=True` will return only ther `_values` field in `metadata`.\n",
    "\n",
    "**Note:**\n",
    "If you return metadata or values, the results will be limited to the top 20.\n",
    "\n",
    "[https://developers.cloudflare.com/vectorize/platform/limits/](https://developers.cloudflare.com/vectorize/platform/limits/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_documents = cfVect.similarity_search(\n",
    "    index_name=vectorize_index_name,\n",
    "    query=\"Workers AI\",\n",
    "    return_values=True,\n",
    "    return_metadata=\"all\",\n",
    "    k=100,\n",
    ")\n",
    "print(f\"{len(query_documents)} results:\\n{str(query_documents[0])[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If you'd like the similarity `scores` to be returned, you can use `similarity_search_with_score`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_documents = cfVect.similarity_search_with_score(\n",
    "    index_name=vectorize_index_name,\n",
    "    query=\"Workers AI\",\n",
    "    k=100,\n",
    "    return_metadata=\"all\",\n",
    ")\n",
    "print(f\"{len(query_documents)} results:\\n{str(query_documents[0])[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Including D1 for \"Raw Values\"\n",
    "All of the `add` and `search` methods on CloudflareVectorize support a `include_d1` parameter (default=True).\n",
    "\n",
    "This is to configure whether you want to store/retrieve raw values.\n",
    "\n",
    "If you do not want to use D1 for this, you can set this to `include=False`.  This will return documents with an empty `page_content` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_documents = cfVect.similarity_search_with_score(\n",
    "    index_name=vectorize_index_name,\n",
    "    query=\"california\",\n",
    "    k=100,\n",
    "    return_metadata=\"all\",\n",
    "    include_d1=False,\n",
    ")\n",
    "print(f\"{len(query_documents)} results:\\n{str(query_documents[0])[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Searching with Metadata Filtering\n",
    "\n",
    "As mentioned before, Vectorize supports filtered search via filtered on indexes metadata fields.  Here is an example where we search for `Introduction` values within the indexed `section` metadata field.\n",
    "\n",
    "More info on searching on Metadata fields is here: [https://developers.cloudflare.com/vectorize/reference/metadata-filtering/](https://developers.cloudflare.com/vectorize/reference/metadata-filtering/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_documents = cfVect.similarity_search_with_score(\n",
    "    index_name=vectorize_index_name,\n",
    "    query=\"California\",\n",
    "    k=100,\n",
    "    md_filter={\"section\": \"Introduction\"},\n",
    "    return_metadata=\"all\",\n",
    ")\n",
    "print(f\"{len(query_documents)} results:\\n - {str(query_documents[:3])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do more sophisticated filtering as well\n",
    "\n",
    "https://developers.cloudflare.com/vectorize/reference/metadata-filtering/#valid-filter-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_documents = cfVect.similarity_search_with_score(\n",
    "    index_name=vectorize_index_name,\n",
    "    query=\"California\",\n",
    "    k=100,\n",
    "    md_filter={\"section\": {\"$ne\": \"Introduction\"}},\n",
    "    return_metadata=\"all\",\n",
    ")\n",
    "print(f\"{len(query_documents)} results:\\n - {str(query_documents[:3])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_documents = cfVect.similarity_search_with_score(\n",
    "    index_name=vectorize_index_name,\n",
    "    query=\"DNS\",\n",
    "    k=100,\n",
    "    md_filter={\"section\": {\"$in\": [\"Products\", \"History\"]}},\n",
    "    return_metadata=\"all\",\n",
    ")\n",
    "print(f\"{len(query_documents)} results:\\n - {str(query_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search by Namespace\n",
    "We can also search for vectors by `namespace`.  We just need to add it to the `namespaces` array when adding it to our vector database.\n",
    "\n",
    "https://developers.cloudflare.com/vectorize/reference/metadata-filtering/#namespace-versus-metadata-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace_name = f\"test-namespace-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "new_documents = [\n",
    "    Document(\n",
    "        page_content=\"This is a new namespace specific document!\",\n",
    "        metadata={\"section\": \"Namespace Test1\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"This is another namespace specific document!\",\n",
    "        metadata={\"section\": \"Namespace Test2\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "r = cfVect.add_documents(\n",
    "    index_name=vectorize_index_name,\n",
    "    documents=new_documents,\n",
    "    namespaces=[namespace_name] * len(new_documents),\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_documents = cfVect.similarity_search(\n",
    "    index_name=vectorize_index_name,\n",
    "    query=\"California\",\n",
    "    namespace=namespace_name,\n",
    ")\n",
    "\n",
    "print(f\"{len(query_documents)} results:\\n - {str(query_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Search by IDs\n",
    "We can also retrieve specific records for specific IDs.  To do so, we need to set the vectorize index name on the `index_name` Vectorize state param.\n",
    "\n",
    "This will return both `_namespace` and `_values` as well as other `metadata`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = [x.id for x in query_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfVect.index_name = vectorize_index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_documents = cfVect.get_by_ids(\n",
    "    sample_ids,\n",
    ")\n",
    "print(str(query_documents[:3])[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The namespace will be included in the `_namespace` field in `metadata` along with your other metadata (if you requested it in `return_metadata`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You cannot set the `_namespace` or `_values` fields in `metadata` as they are reserved.  They will be stripped out during the insert process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upserts\n",
    "\n",
    "Vectorize supports Upserts which you can perform by setting `upsert=True`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_documents[0].page_content = \"Updated: \" + query_documents[0].page_content\n",
    "print(query_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_document_id = \"12345678910\"\n",
    "new_document = Document(\n",
    "    id=new_document_id,\n",
    "    page_content=\"This is a new document!\",\n",
    "    metadata={\"section\": \"Introduction\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = cfVect.add_documents(\n",
    "    index_name=vectorize_index_name,\n",
    "    documents=[new_document, query_documents[0]],\n",
    "    upsert=True,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_documents_updated = cfVect.get_by_ids([new_document_id, query_documents[0].id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(query_documents_updated[0])[:500])\n",
    "print(query_documents_updated[0].page_content)\n",
    "print(query_documents_updated[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Deleting Records\n",
    "We can delete records by their ids as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = cfVect.delete(index_name=vectorize_index_name, ids=sample_ids, wait=True)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And to confirm deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_documents = cfVect.get_by_ids(sample_ids)\n",
    "assert len(query_documents) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating from Documents\n",
    "LangChain stipulates that all vectorstores must have a `from_documents` method to instantiate a new Vectorstore from documents.  This is a more streamlined method than the individual `create, add` steps shown above.\n",
    "\n",
    "You can do that as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorize_index_name = \"test-langchain-from-docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfVect = CloudflareVectorize.from_documents(\n",
    "    account_id=cf_acct_id,\n",
    "    index_name=vectorize_index_name,\n",
    "    documents=texts,\n",
    "    embedding=embedder,\n",
    "    d1_database_id=d1_database_id,\n",
    "    d1_api_token=cf_d1_token,\n",
    "    vectorize_api_token=cf_vectorize_token,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# query for documents\n",
    "query_documents = cfVect.similarity_search(\n",
    "    index_name=vectorize_index_name,\n",
    "    query=\"Edge Computing\",\n",
    ")\n",
    "\n",
    "print(f\"{len(query_documents)} results:\\n{str(query_documents[0])[:300]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Async Examples\n",
    "This section will show some Async examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Creating Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:37:16.194391Z",
     "start_time": "2025-04-02T20:37:16.192334Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorize_index_name1 = \"test-langchain1\"\n",
    "vectorize_index_name2 = \"test-langchain2\"\n",
    "vectorize_index_name3 = \"test-langchain3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:37:21.121217Z",
     "start_time": "2025-04-02T20:37:18.123453Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# depending on your notebook environment you might need to include these:\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "async_requests = [\n",
    "    cfVect.acreate_index(index_name=vectorize_index_name1),\n",
    "    cfVect.acreate_index(index_name=vectorize_index_name2),\n",
    "    cfVect.acreate_index(index_name=vectorize_index_name3),\n",
    "]\n",
    "\n",
    "await asyncio.gather(*async_requests);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Creating Metadata Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:39:31.424777Z",
     "start_time": "2025-04-02T20:37:31.260540Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "async_requests = [\n",
    "    cfVect.acreate_metadata_index(\n",
    "        property_name=\"section\",\n",
    "        index_type=\"string\",\n",
    "        index_name=vectorize_index_name1,\n",
    "        wait=True,\n",
    "    ),\n",
    "    cfVect.acreate_metadata_index(\n",
    "        property_name=\"section\",\n",
    "        index_type=\"string\",\n",
    "        index_name=vectorize_index_name2,\n",
    "        wait=True,\n",
    "    ),\n",
    "    cfVect.acreate_metadata_index(\n",
    "        property_name=\"section\",\n",
    "        index_type=\"string\",\n",
    "        index_name=vectorize_index_name3,\n",
    "        wait=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "await asyncio.gather(*async_requests);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Adding Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:41:48.654638Z",
     "start_time": "2025-04-02T20:40:13.169140Z"
    }
   },
   "outputs": [],
   "source": [
    "async_requests = [\n",
    "    cfVect.aadd_documents(index_name=vectorize_index_name1, documents=texts, wait=True),\n",
    "    cfVect.aadd_documents(index_name=vectorize_index_name2, documents=texts, wait=True),\n",
    "    cfVect.aadd_documents(index_name=vectorize_index_name3, documents=texts, wait=True),\n",
    "]\n",
    "\n",
    "await asyncio.gather(*async_requests);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Querying/Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:43:23.485539Z",
     "start_time": "2025-04-02T20:43:19.319179Z"
    }
   },
   "outputs": [],
   "source": [
    "async_requests = [\n",
    "    cfVect.asimilarity_search(index_name=vectorize_index_name1, query=\"Workers AI\"),\n",
    "    cfVect.asimilarity_search(index_name=vectorize_index_name2, query=\"Edge Computing\"),\n",
    "    cfVect.asimilarity_search(index_name=vectorize_index_name3, query=\"SASE\"),\n",
    "]\n",
    "\n",
    "async_results = await asyncio.gather(*async_requests);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:43:23.498499Z",
     "start_time": "2025-04-02T20:43:23.495367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 results:\n",
      "page_content='In 2023, Cloudflare launched Workers AI, a framework allowing for use of Nvidia GPU's within'\n",
      "20 results:\n",
      "page_content='utilizing edge computing, reverse proxies for web traffic, data center interconnects, and a content'\n",
      "20 results:\n",
      "page_content='== Products =='\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(async_results[0])} results:\\n{str(async_results[0][0])[:300]}\")\n",
    "print(f\"{len(async_results[1])} results:\\n{str(async_results[1][0])[:300]}\")\n",
    "print(f\"{len(async_results[1])} results:\\n{str(async_results[2][0])[:300]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Returning Metadata/Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:43:29.280561Z",
     "start_time": "2025-04-02T20:43:27.087132Z"
    }
   },
   "outputs": [],
   "source": [
    "async_requests = [\n",
    "    cfVect.asimilarity_search(\n",
    "        index_name=vectorize_index_name1,\n",
    "        query=\"California\",\n",
    "        return_values=True,\n",
    "        return_metadata=\"all\",\n",
    "    ),\n",
    "    cfVect.asimilarity_search(\n",
    "        index_name=vectorize_index_name2,\n",
    "        query=\"California\",\n",
    "        return_values=True,\n",
    "        return_metadata=\"all\",\n",
    "    ),\n",
    "    cfVect.asimilarity_search(\n",
    "        index_name=vectorize_index_name3,\n",
    "        query=\"California\",\n",
    "        return_values=True,\n",
    "        return_metadata=\"all\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "async_results = await asyncio.gather(*async_requests);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:43:29.287664Z",
     "start_time": "2025-04-02T20:43:29.284749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 results:\n",
      "page_content='and other services. Cloudflare's headquarters are in San Francisco, California. According to' metadata={'section': 'Introduction', '_values': [-0.028919144, -0.019105384, -0.000850724, 0.012162158, 0.01853957, -0.028224546, -0.007677764, 0.0024373678, 0.041417565, -0.013160827, 0.03270\n",
      "20 results:\n",
      "page_content='and other services. Cloudflare's headquarters are in San Francisco, California. According to' metadata={'section': 'Introduction', '_values': [-0.028919144, -0.019105384, -0.000850724, 0.012162158, 0.01853957, -0.028224546, -0.007677764, 0.0024373678, 0.041417565, -0.013160827, 0.03270\n",
      "20 results:\n",
      "page_content='and other services. Cloudflare's headquarters are in San Francisco, California. According to' metadata={'section': 'Introduction', '_values': [-0.028919144, -0.019105384, -0.000850724, 0.012162158, 0.01853957, -0.028224546, -0.007677764, 0.0024373678, 0.041417565, -0.013160827, 0.03270\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(async_results[0])} results:\\n{str(async_results[0][0])[:300]}\")\n",
    "print(f\"{len(async_results[1])} results:\\n{str(async_results[1][0])[:300]}\")\n",
    "print(f\"{len(async_results[1])} results:\\n{str(async_results[2][0])[:300]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching with Metadata Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:43:34.431499Z",
     "start_time": "2025-04-02T20:43:32.851262Z"
    }
   },
   "outputs": [],
   "source": [
    "async_requests = [\n",
    "    cfVect.asimilarity_search(\n",
    "        index_name=vectorize_index_name1,\n",
    "        query=\"Cloudflare services\",\n",
    "        k=2,\n",
    "        md_filter={\"section\": \"Products\"},\n",
    "        return_metadata=\"all\",\n",
    "        # return_values=True\n",
    "    ),\n",
    "    cfVect.asimilarity_search(\n",
    "        index_name=vectorize_index_name2,\n",
    "        query=\"Cloudflare services\",\n",
    "        k=2,\n",
    "        md_filter={\"section\": \"Products\"},\n",
    "        return_metadata=\"all\",\n",
    "        # return_values=True\n",
    "    ),\n",
    "    cfVect.asimilarity_search(\n",
    "        index_name=vectorize_index_name3,\n",
    "        query=\"Cloudflare services\",\n",
    "        k=2,\n",
    "        md_filter={\"section\": \"Products\"},\n",
    "        return_metadata=\"all\",\n",
    "        # return_values=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "async_results = await asyncio.gather(*async_requests);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:43:34.437875Z",
     "start_time": "2025-04-02T20:43:34.435146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc.metadata[\"section\"] == \"Products\" for doc in async_results[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:43:35.690761Z",
     "start_time": "2025-04-02T20:43:35.688023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 results:\n",
      "page_content='Cloudflare also provides analysis and reports on large-scale outages, including Verizon’s October' metadata={'section': 'Products'}\n",
      "2 results:\n",
      "page_content='Cloudflare provides network and security products for consumers and businesses, utilizing edge' metadata={'section': 'Products'}\n",
      "2 results:\n",
      "page_content='Cloudflare provides network and security products for consumers and businesses, utilizing edge' metadata={'section': 'Products'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(async_results[0])} results:\\n{str(async_results[0][-1])[:300]}\")\n",
    "print(f\"{len(async_results[1])} results:\\n{str(async_results[1][0])[:300]}\")\n",
    "print(f\"{len(async_results[1])} results:\\n{str(async_results[2][0])[:300]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Let's finish by deleting all of the indexes we created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:43:39.393445Z",
     "start_time": "2025-04-02T20:43:39.136998Z"
    }
   },
   "outputs": [],
   "source": [
    "arr_indexes = cfVect.list_indexes()\n",
    "arr_indexes = [x for x in arr_indexes if \"test-langchain\" in x.get(\"name\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T20:43:41.843703Z",
     "start_time": "2025-04-02T20:43:39.730074Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr_async_requests = [\n",
    "    cfVect.adelete_index(index_name=x.get(\"name\")) for x in arr_indexes\n",
    "]\n",
    "await asyncio.gather(*arr_async_requests);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Reference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developers.cloudflare.com/api/resources/vectorize/\n",
    "\n",
    "https://developers.cloudflare.com/vectorize/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc-langchain-G_cWTCcf-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
